{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataCrunch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IBtXgFsW3Jfv",
        "jYstog5M3YPp",
        "PFHZO9FNMkLp",
        "YXalwoJWMtkw",
        "mw1l15DghQ0Q"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DAG00DAG33/Hackaton-DataCrunch/blob/main/DataCrunch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd2LBIIWixP_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "import requests\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNVUHNOno9ji"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L052V0vr3yEw",
        "outputId": "1239b588-f152-4a5e-b460-e31abd498705"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "path = \"/gdrive/MyDrive/ML/DataCrunch/models/\"\n",
        "\n",
        "training_data = pd.read_pickle(\"/gdrive/MyDrive/ML/DataCrunch/data/train_test_hackathon.pkl\")\n",
        "\n",
        "\n",
        "# Targets to be predicted\n",
        "targets = training_data[training_data.columns[-3:]]\n",
        "\n",
        "# Using target as feature is a bad idea\n",
        "for target in ['target_r', 'target_g', 'target_b']:\n",
        "    training_data = training_data.drop(target, axis=1)\n",
        "\n",
        "# Data for which you will submit your prediction\n",
        "hackathon_data = pd.read_pickle(\"/gdrive/MyDrive/ML/DataCrunch/data/hackathon_data.pkl\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s7dY7gBym76"
      },
      "source": [
        "path = \"/gdrive/MyDrive/ML/DataCrunch/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "nDH7smCHVO81",
        "outputId": "88dacaef-4c15-400a-c6ae-f5fa0f664aca"
      },
      "source": [
        "\"\"\"# Data Download (may take a few minutes depending on your network)\n",
        "train_datalink = 'http://hackathon.datacrunch.com/data/train_test_hackathon.pkl'\n",
        "hackathon_data_link = 'http://hackathon.datacrunch.com/data/hackathon_data.pkl'\n",
        "\n",
        "# Data for training\n",
        "training_data = pd.read_pickle(train_datalink)\n",
        "\n",
        "# Targets to be predicted\n",
        "targets = training_data[training_data.columns[-3:]]\n",
        "\n",
        "# Using target as feature is a bad idea\n",
        "for target in ['target_r', 'target_g', 'target_b']:\n",
        "    training_data = training_data.drop(target, axis=1)\n",
        "\n",
        "# Data for which you will submit your prediction\n",
        "hackathon_data = pd.read_pickle(hackathon_data_link)\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"# Data Download (may take a few minutes depending on your network)\\ntrain_datalink = 'http://hackathon.datacrunch.com/data/train_test_hackathon.pkl'\\nhackathon_data_link = 'http://hackathon.datacrunch.com/data/hackathon_data.pkl'\\n\\n# Data for training\\ntraining_data = pd.read_pickle(train_datalink)\\n\\n# Targets to be predicted\\ntargets = training_data[training_data.columns[-3:]]\\n\\n# Using target as feature is a bad idea\\nfor target in ['target_r', 'target_g', 'target_b']:\\n    training_data = training_data.drop(target, axis=1)\\n\\n# Data for which you will submit your prediction\\nhackathon_data = pd.read_pickle(hackathon_data_link)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9CjZYh8jPwW"
      },
      "source": [
        "binary_atr = ['Feature_14_cv_bool', 'Feature_15_cv_bool', 'Feature_16_cv_bool', 'Feature_17_cv_bool', 'Feature_18_adv_cv_bool', 'Feature_19_adv_cv_bool', 'Feature_20_adv_cv_bool', 'Feature_21_adv_cv_bool', 'Feature_22_adv_cv_bool']\n",
        "enum_atr = ['Feature_1_cv_enum', 'Feature_23_adv_cv_enum']\n",
        "targets_atr = ['target_r', 'target_g', 'target_b']\n",
        "nan_atr = ['Feature_7', 'Feature_8', 'Feature_9', 'Feature_11']\n",
        "cols_to_norm = [\"Feature_2\", \"Feature_3\", \"Feature_4\", \"Feature_6\", \"Feature_7\", \"Feature_11\"]\n",
        "atributes = [atr for atr in training_data.columns if atr not in targets_atr]\n",
        "numeric_atr = [atr for atr in atributes if atr not in (binary_atr + enum_atr)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "gVCga88xMMeA",
        "outputId": "3552b1e6-e73b-421a-9cc8-f2d5328b6f91"
      },
      "source": [
        "training_data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature_1_cv_enum</th>\n",
              "      <th>Feature_2</th>\n",
              "      <th>Feature_3</th>\n",
              "      <th>Feature_4</th>\n",
              "      <th>Feature_5</th>\n",
              "      <th>Feature_6</th>\n",
              "      <th>Feature_7</th>\n",
              "      <th>Feature_8</th>\n",
              "      <th>Feature_9</th>\n",
              "      <th>Feature_10</th>\n",
              "      <th>Feature_11</th>\n",
              "      <th>Feature_12</th>\n",
              "      <th>Feature_13</th>\n",
              "      <th>Feature_14_cv_bool</th>\n",
              "      <th>Feature_15_cv_bool</th>\n",
              "      <th>Feature_16_cv_bool</th>\n",
              "      <th>Feature_17_cv_bool</th>\n",
              "      <th>Feature_18_adv_cv_bool</th>\n",
              "      <th>Feature_19_adv_cv_bool</th>\n",
              "      <th>Feature_20_adv_cv_bool</th>\n",
              "      <th>Feature_21_adv_cv_bool</th>\n",
              "      <th>Feature_22_adv_cv_bool</th>\n",
              "      <th>Feature_23_adv_cv_enum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>300000.000000</td>\n",
              "      <td>3.000000e+05</td>\n",
              "      <td>3.000000e+05</td>\n",
              "      <td>3.000000e+05</td>\n",
              "      <td>3.000000e+05</td>\n",
              "      <td>3.000000e+05</td>\n",
              "      <td>2.046110e+05</td>\n",
              "      <td>214564.000000</td>\n",
              "      <td>204506.000000</td>\n",
              "      <td>3.000000e+05</td>\n",
              "      <td>2.610880e+05</td>\n",
              "      <td>3.000000e+05</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.367430</td>\n",
              "      <td>3.768100e+05</td>\n",
              "      <td>3.093938e+06</td>\n",
              "      <td>3.704056e+05</td>\n",
              "      <td>3.601329e+03</td>\n",
              "      <td>3.776893e+05</td>\n",
              "      <td>1.490732e+04</td>\n",
              "      <td>2519.349161</td>\n",
              "      <td>-0.020086</td>\n",
              "      <td>4.908759e+10</td>\n",
              "      <td>8.380347e+09</td>\n",
              "      <td>inf</td>\n",
              "      <td>0.665203</td>\n",
              "      <td>0.490037</td>\n",
              "      <td>0.410513</td>\n",
              "      <td>0.023157</td>\n",
              "      <td>0.076293</td>\n",
              "      <td>0.084870</td>\n",
              "      <td>0.022287</td>\n",
              "      <td>0.133607</td>\n",
              "      <td>0.198230</td>\n",
              "      <td>0.623147</td>\n",
              "      <td>3.201337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.723846</td>\n",
              "      <td>3.832078e+07</td>\n",
              "      <td>2.439559e+08</td>\n",
              "      <td>3.847110e+07</td>\n",
              "      <td>8.185623e+05</td>\n",
              "      <td>3.832163e+07</td>\n",
              "      <td>2.762918e+06</td>\n",
              "      <td>308.948786</td>\n",
              "      <td>1.608483</td>\n",
              "      <td>1.254558e+13</td>\n",
              "      <td>2.731617e+12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.471920</td>\n",
              "      <td>0.499902</td>\n",
              "      <td>0.491928</td>\n",
              "      <td>0.150401</td>\n",
              "      <td>0.265467</td>\n",
              "      <td>0.278689</td>\n",
              "      <td>0.147615</td>\n",
              "      <td>0.340230</td>\n",
              "      <td>0.398667</td>\n",
              "      <td>0.484598</td>\n",
              "      <td>1.247063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.008232e+09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-3.433611e+00</td>\n",
              "      <td>1851.859985</td>\n",
              "      <td>-6.495034</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-2.060307e+07</td>\n",
              "      <td>7.331550e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.090000e+02</td>\n",
              "      <td>1.395000e+04</td>\n",
              "      <td>7.340000e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>8.140000e+02</td>\n",
              "      <td>1.318669e+01</td>\n",
              "      <td>2274.639893</td>\n",
              "      <td>-0.281288</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.189688e+05</td>\n",
              "      <td>1.502053e-02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.204000e+03</td>\n",
              "      <td>4.147417e+04</td>\n",
              "      <td>3.000000e+03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.233000e+03</td>\n",
              "      <td>2.766816e+01</td>\n",
              "      <td>2601.419922</td>\n",
              "      <td>-0.084317</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.015865e+06</td>\n",
              "      <td>8.967701e-02</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.250000e+04</td>\n",
              "      <td>1.575090e+05</td>\n",
              "      <td>1.150800e+04</td>\n",
              "      <td>1.558000e+01</td>\n",
              "      <td>1.265800e+04</td>\n",
              "      <td>5.547611e+01</td>\n",
              "      <td>2779.030029</td>\n",
              "      <td>0.128861</td>\n",
              "      <td>1.999371e+04</td>\n",
              "      <td>3.572125e+06</td>\n",
              "      <td>2.722777e-01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.310950e+10</td>\n",
              "      <td>9.222350e+10</td>\n",
              "      <td>1.310950e+10</td>\n",
              "      <td>3.000000e+08</td>\n",
              "      <td>1.310950e+10</td>\n",
              "      <td>6.822500e+08</td>\n",
              "      <td>3025.860107</td>\n",
              "      <td>448.924598</td>\n",
              "      <td>4.504504e+15</td>\n",
              "      <td>1.266173e+15</td>\n",
              "      <td>inf</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Feature_1_cv_enum  ...  Feature_23_adv_cv_enum\n",
              "count      300000.000000  ...           300000.000000\n",
              "mean            2.367430  ...                3.201337\n",
              "std             0.723846  ...                1.247063\n",
              "min             0.000000  ...                0.000000\n",
              "25%             2.000000  ...                3.000000\n",
              "50%             2.000000  ...                4.000000\n",
              "75%             3.000000  ...                4.000000\n",
              "max             3.000000  ...                4.000000\n",
              "\n",
              "[8 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6f2Yuz2vUbb"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, atr_names):\n",
        "    self.atr_names = atr_names\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  def transform(self, data):\n",
        "    #print(\"dataFrameSel....\")\n",
        "    return data[self.atr_names]\n",
        "\n",
        "class Log_data(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  def transform(self, data):\n",
        "    #print(\"log...\")\n",
        "    return np.log(np.asarray(data))\n",
        "\n",
        "class RemoveInf(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  def transform(self, data):\n",
        "    #print(\"inf...\")\n",
        "    return pd.DataFrame(data).replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "class ExtraFeature(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  def transform(self, data):\n",
        "    data[\"Feature_nan\"] = pd.isna(data[\"Feature_7\"]).astype(int)\n",
        "    #print(\"aaa\")\n",
        "    #print(data.columns)\n",
        "    return data.values\n",
        "\n",
        "\"\"\"class Add_nan(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  def transform(self, data):\n",
        "    #print(\"inf...\")\n",
        "    return pd.DataFrame(data).replace([np.inf, -np.inf], np.nan)\"\"\"\n",
        "\n",
        "enum_pipeline = Pipeline([\n",
        "                ('selector', DataFrameSelector(enum_atr)),\n",
        "                ('inputer', SimpleImputer(strategy=\"most_frequent\")),\n",
        "                ('oneHotEncoder', OneHotEncoder()),\n",
        "])\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "                ('selector', DataFrameSelector(numeric_atr)),\n",
        "                ('remove_inf', RemoveInf()),\n",
        "                ('include_nan', ExtraFeature()),\n",
        "                ('inputer', SimpleImputer(strategy=\"median\")),\n",
        "                ('log', Log_data()),\n",
        "                ('remove_inf2', RemoveInf()),\n",
        "                ('std_scaler', StandardScaler()),\n",
        "                ('inputer2', SimpleImputer(strategy=\"constant\", fill_value = 10)),\n",
        "])\n",
        "\n",
        "bin_pipeline = Pipeline([\n",
        "                ('selector', DataFrameSelector(binary_atr)),\n",
        "                ('inputer', SimpleImputer(strategy=\"most_frequent\")),\n",
        "])\n",
        "\n",
        "full_pipeline = FeatureUnion(transformer_list = [\n",
        "                ('enum_pipeline', enum_pipeline),\n",
        "                ('num_pipeline', num_pipeline),\n",
        "                ('bin_pipeline', bin_pipeline),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSWnlkkp3fNI",
        "outputId": "78094116-4273-4316-a78d-8d7cd888e2b5"
      },
      "source": [
        "X = pd.DataFrame(full_pipeline.fit_transform(training_data).toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in log\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "Ffo9-vNJB7tl",
        "outputId": "c8d40eb8-673a-43d0-9dae-19d1ee6e49c3"
      },
      "source": [
        "X.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.00000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>3.000000e+05</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>3.000000e+05</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>3.000000e+05</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>3.000000e+05</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "      <td>300000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.023157</td>\n",
              "      <td>0.076293</td>\n",
              "      <td>0.410513</td>\n",
              "      <td>0.490037</td>\n",
              "      <td>0.084870</td>\n",
              "      <td>0.02076</td>\n",
              "      <td>0.125680</td>\n",
              "      <td>0.145543</td>\n",
              "      <td>0.623147</td>\n",
              "      <td>2.735153e-16</td>\n",
              "      <td>0.029567</td>\n",
              "      <td>0.138000</td>\n",
              "      <td>5.546767</td>\n",
              "      <td>-9.979504e-16</td>\n",
              "      <td>0.001967</td>\n",
              "      <td>1.194786e-14</td>\n",
              "      <td>7.358000</td>\n",
              "      <td>5.546767</td>\n",
              "      <td>0.011333</td>\n",
              "      <td>2.301639e-16</td>\n",
              "      <td>3.347967</td>\n",
              "      <td>6.820367</td>\n",
              "      <td>0.490037</td>\n",
              "      <td>0.410513</td>\n",
              "      <td>0.023157</td>\n",
              "      <td>0.076293</td>\n",
              "      <td>0.084870</td>\n",
              "      <td>0.022287</td>\n",
              "      <td>0.133607</td>\n",
              "      <td>0.198230</td>\n",
              "      <td>0.623147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.150401</td>\n",
              "      <td>0.265467</td>\n",
              "      <td>0.491928</td>\n",
              "      <td>0.499902</td>\n",
              "      <td>0.278689</td>\n",
              "      <td>0.14258</td>\n",
              "      <td>0.331489</td>\n",
              "      <td>0.352648</td>\n",
              "      <td>0.484598</td>\n",
              "      <td>1.000002e+00</td>\n",
              "      <td>1.136591</td>\n",
              "      <td>1.532046</td>\n",
              "      <td>5.014624</td>\n",
              "      <td>1.000002e+00</td>\n",
              "      <td>1.009688</td>\n",
              "      <td>1.000002e+00</td>\n",
              "      <td>4.438930</td>\n",
              "      <td>5.014624</td>\n",
              "      <td>1.054550</td>\n",
              "      <td>1.000002e+00</td>\n",
              "      <td>4.719201</td>\n",
              "      <td>4.656859</td>\n",
              "      <td>0.499902</td>\n",
              "      <td>0.491928</td>\n",
              "      <td>0.150401</td>\n",
              "      <td>0.265467</td>\n",
              "      <td>0.278689</td>\n",
              "      <td>0.147615</td>\n",
              "      <td>0.340230</td>\n",
              "      <td>0.398667</td>\n",
              "      <td>0.484598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.292658e+00</td>\n",
              "      <td>-4.896712</td>\n",
              "      <td>-3.278524</td>\n",
              "      <td>-9.336277</td>\n",
              "      <td>-3.293090e+00</td>\n",
              "      <td>-13.858513</td>\n",
              "      <td>-2.847422e+00</td>\n",
              "      <td>-6.859854</td>\n",
              "      <td>-6.006601</td>\n",
              "      <td>-11.186259</td>\n",
              "      <td>-5.917666e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.323504e-01</td>\n",
              "      <td>-0.611423</td>\n",
              "      <td>-0.518399</td>\n",
              "      <td>0.274328</td>\n",
              "      <td>-5.321209e-01</td>\n",
              "      <td>-0.254233</td>\n",
              "      <td>-5.093937e-01</td>\n",
              "      <td>1.397395</td>\n",
              "      <td>0.111988</td>\n",
              "      <td>-0.549330</td>\n",
              "      <td>-5.539180e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.504520e-02</td>\n",
              "      <td>-0.123062</td>\n",
              "      <td>0.044777</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.606251e-02</td>\n",
              "      <td>0.085323</td>\n",
              "      <td>2.615084e-01</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>-0.068417</td>\n",
              "      <td>2.266096e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.962456e-01</td>\n",
              "      <td>0.479308</td>\n",
              "      <td>0.613408</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.983439e-01</td>\n",
              "      <td>0.422255</td>\n",
              "      <td>6.775223e-01</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.451488</td>\n",
              "      <td>7.107365e-01</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.311242e+00</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>6.304280e+00</td>\n",
              "      <td>16.085422</td>\n",
              "      <td>1.644042e+00</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.506698</td>\n",
              "      <td>10.543031</td>\n",
              "      <td>8.474949e+00</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0              1   ...             29             30\n",
              "count  300000.000000  300000.000000  ...  300000.000000  300000.000000\n",
              "mean        0.023157       0.076293  ...       0.198230       0.623147\n",
              "std         0.150401       0.265467  ...       0.398667       0.484598\n",
              "min         0.000000       0.000000  ...       0.000000       0.000000\n",
              "25%         0.000000       0.000000  ...       0.000000       0.000000\n",
              "50%         0.000000       0.000000  ...       0.000000       1.000000\n",
              "75%         0.000000       0.000000  ...       0.000000       1.000000\n",
              "max         1.000000       1.000000  ...       1.000000       1.000000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "8yo65hBS1Wwp",
        "outputId": "3cf9a4f4-ff0f-4fe8-e083-f863231ad442"
      },
      "source": [
        "y = targets\n",
        "\n",
        "#20% validation 20% test  60% train\n",
        "#60000          60000     180000\n",
        "\n",
        "X_d, X_val, y_d, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_d, y_d, test_size=0.25, random_state=42)\n",
        "\n",
        "\"\"\"X_pca_d, X_val_pca, y_d, y_val = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca_d, y_d, test_size=0.25, random_state=42)\n",
        "\n",
        "X_drop_d, X_val_drop, y_d, y_val = train_test_split(X_drop, y, test_size=0.2, random_state=42)\n",
        "X_train_drop, X_test_drop, y_train, y_test = train_test_split(X_drop_d, y_d, test_size=0.25, random_state=42)\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_pca_d, X_val_pca, y_d, y_val = train_test_split(X_pca, y, test_size=0.2, random_state=42)\\nX_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca_d, y_d, test_size=0.25, random_state=42)\\n\\nX_drop_d, X_val_drop, y_d, y_val = train_test_split(X_drop, y, test_size=0.2, random_state=42)\\nX_train_drop, X_test_drop, y_train, y_test = train_test_split(X_drop_d, y_d, test_size=0.25, random_state=42)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWBUjNmS6Len",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3a741c-af8d-40ac-b74e-070de3d5d968"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180000, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBjpRK4cD2Lm"
      },
      "source": [
        "def bin(n, s):\n",
        "  arr = np.zeros((s))\n",
        "  for i in range(s - 1, -1, -1):\n",
        "    if n >= pow(2, i):\n",
        "      arr[s - i - 1] = 1\n",
        "      n -= pow(2, i)\n",
        "      #print(pow(2, i), i)\n",
        "  return arr\n",
        "\n",
        "\"\"\"\n",
        "Compara las predicciones de n modelos y las reales para ver como de correlacionados son los resultados\n",
        "luego he descubierto que era mas facil con spearman\n",
        "\"\"\"\n",
        "def compare(preds, y):\n",
        "  preds = np.asarray(preds).transpose()\n",
        "  y = np.asarray(y)\n",
        "  arr = np.concatenate((preds, y), axis=1)\n",
        "  di = [0] * pow(2, arr.shape[1]);\n",
        "  #for i in range(pow(2, arr.shape[1])):\n",
        "   # di[i] = 0\n",
        "  for i in range(pow(2, arr.shape[1])):\n",
        "    for j in range(arr.shape[0]):\n",
        "      if np.all(arr[j] == bin(i, arr.shape[1])):\n",
        "        di[i] = di[i] + 1\n",
        "        #print(i, j)\n",
        "  for i in range(pow(2, arr.shape[1])):\n",
        "    print(bin(i, arr.shape[1]), \"\\t\",  di[i]/arr.shape[0])\n",
        "  print()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuczDRXOyB6Y"
      },
      "source": [
        "def compareModel(model1, model2):\n",
        "  X_pred1 = model1.predict(X_test)\n",
        "  X_pred2 = model2.predict(X_test)\n",
        "\n",
        "  compare([X_pred1[:, 0], X_pred2[:, 0]], y_test.values[:, 0].reshape(-1, 1))\n",
        "  compare([X_pred1[:, 1], X_pred2[:, 1]], y_test.values[:, 1].reshape(-1, 1))\n",
        "  compare([X_pred1[:, 2], X_pred2[:, 2]], y_test.values[:, 2].reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wrqv5FkDoWg",
        "outputId": "7f78219e-0979-4eca-949f-d33bc9b8d63b"
      },
      "source": [
        "bin(63,10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQEW-bVtG7sa"
      },
      "source": [
        "def accuracy(model, x, y):\n",
        "  y = y.reshape(x.shape[0], -1)\n",
        "  #print(y.shape)\n",
        "  y_pred = model.predict(x).reshape(x.shape[0], -1)\n",
        "  y_pred_p = (y_pred > 0.5).astype(int)\n",
        "\n",
        "  for j in range(y_pred_p.shape[1]):\n",
        "    good = 0\n",
        "    tot = 0\n",
        "    for i in range(y_pred_p.shape[0]):\n",
        "      if y_pred_p[i][j] == y[i][j]:\n",
        "        good += 1\n",
        "      tot += 1\n",
        "    print(good/tot)\n",
        "    #print(y_pred)\n",
        "  print()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZSE62RgIcdZ"
      },
      "source": [
        "#Table of models\n",
        "| |train|test|val|\n",
        "|-|-----|----|---|\n",
        "|forest||(83'82 84'58 85'34)|(84'09 84'57 85'55)|\n",
        "|forest_drop||(82'29 83'11 84'15)|(82'64 83'19 84'11)|\n",
        "|forest_pca||(73'50 74'71 76'25)|(73'82 74'31 76'39)|\n",
        "|forest_join||(79'97 80'79 81'89)|(80'17 80'77 81'80)|\n",
        "|||||\n",
        "|extra||(73'24 74'02 75'65)|(72'93 73'90 75'88)|\n",
        "|||||\n",
        "|ada1||(78'89 79'37 80'78)|(78'96 79'75 80'78)|\n",
        "|ada2||||\n",
        "|||||\n",
        "|neigh||(66'77 67'63 69'33)|(66'77 67'67 69'18)|\n",
        "|||||\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBtXgFsW3Jfv"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO2jdfsN7PaZ"
      },
      "source": [
        "from keras.layers import Input, Dense, Dropout, BatchNormalization  \n",
        "from keras.models import Model\n",
        "\n",
        "def model(len):\n",
        "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
        "    X_input = Input(len)\n",
        "\n",
        "    X = BatchNormalization()(X_input)\n",
        "    X = Dropout(0.1)(X)\n",
        "    X = Dense(30, activation = \"relu\")(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Dropout(0.3)(X)\n",
        "    X = Dense(30, activation = \"relu\")(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Dropout(0.3)(X)\n",
        "    X = Dense(10, activation = \"relu\")(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Dense(10, activation = \"relu\")(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Dense(10, activation = \"relu\")(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Dense(3, activation='sigmoid')(X)\n",
        "\n",
        "\n",
        "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
        "    model = Model(inputs = X_input, outputs = X, name='test_model')\n",
        "\n",
        "    return model\n",
        "\n",
        "test_model = model(X2.shape[1])\n",
        "test_model.compile(loss='BinaryCrossentropy') #BinaryCrossentropy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g6PEVc6UMaE"
      },
      "source": [
        "history  = test_model.fit(X2, np.array(y_train), epochs = 20, batch_size = 1000)\n",
        "plt.plot(history.history['loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjZR43WOgHS5"
      },
      "source": [
        "test_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYstog5M3YPp"
      },
      "source": [
        "#Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X05wth55BeB0"
      },
      "source": [
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree_clf = DecisionTreeClassifier()\n",
        "tree_clf.fit(X_train, y_train.values[:, 0])\n",
        "y_pred = tree_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFvgyyeWE1id",
        "outputId": "d6c04cbd-d1a4-44ea-c663-76279dcabc38"
      },
      "source": [
        "accuracy(tree_clf, X_test, y_test.values[:, 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7746166666666666\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewMRC2qHFD8Z",
        "outputId": "bbeeeb2a-387a-4564-8cc7-65363a0c271b"
      },
      "source": [
        "compare([y_pred, y_pred], y_test.values[:, 0].reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0.] \t 0.4629666666666667\n",
            "[0. 0. 1.] \t 0.1128\n",
            "[0. 1. 0.] \t 0.0\n",
            "[0. 1. 1.] \t 0.0\n",
            "[1. 0. 0.] \t 0.0\n",
            "[1. 0. 1.] \t 0.0\n",
            "[1. 1. 0.] \t 0.11258333333333333\n",
            "[1. 1. 1.] \t 0.31165\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuknGh693dIR"
      },
      "source": [
        "#Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFHZO9FNMkLp"
      },
      "source": [
        "##Normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVggMzXacb8s",
        "outputId": "e833b9c3-8bee-4380-c4e1-3aea25aaefa7"
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "\n",
        "class ForestSep(BaseEstimator, ClassifierMixin): #uno para cada parametro a predecir. Luego vi que no mejora a un solo modelo para los 3\n",
        "  def __init__(self, n_estimators = 1000):\n",
        "    self.forest_1 = RandomForestClassifier(bootstrap=False, max_features=20, n_estimators = n_estimators)\n",
        "    self.forest_2 = RandomForestClassifier(bootstrap=False, max_features=20, n_estimators = n_estimators)\n",
        "    self.forest_3 = RandomForestClassifier(bootstrap=False, max_features=20, n_estimators = n_estimators)\n",
        "  def fit(self, X, y):\n",
        "    y = np.asarray(y)\n",
        "    self.forest_1.fit(X, y[:, 0])\n",
        "    print(\"trained 1\")\n",
        "    self.forest_2.fit(X, y[:, 1])\n",
        "    print(\"trained 2\")\n",
        "    self.forest_3.fit(X, y[:, 2])\n",
        "    print(\"trained 3\")\n",
        "  def predict(self, X):\n",
        "    pred_1 = self.forest_1.predict(X).reshape(-1, 1)\n",
        "    pred_2 = self.forest_2.predict(X).reshape(-1, 1)\n",
        "    pred_3 = self.forest_3.predict(X).reshape(-1, 1)\n",
        "    return np.concatenate((pred_1, pred_2, pred_3), axis = 1)\n",
        "  def predict_proba(self, x):\n",
        "    pred_1 = self.forest_1.predict_proba(X).reshape(-1, 1)\n",
        "    pred_2 = self.forest_2.predict_proba(X).reshape(-1, 1)\n",
        "    pred_3 = self.forest_3.predict_proba(X).reshape(-1, 1)\n",
        "    return np.concatenate((pred_1, pred_2, pred_3), axis = 1)\n",
        "\n",
        "#forest_sep = ForestSep(n_estimators = 10)\n",
        "forest_tog = RandomForestClassifier(bootstrap=False, max_features=20, n_estimators= 300)\n",
        "\n",
        "t = time.time()\n",
        "#forest_sep.fit(X_train, y_train.values)\n",
        "#forest_tog.fit(X_train, y_train)\n",
        "print(time.time() - t)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "957.5377616882324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC9DArzKeOuj",
        "outputId": "0fa33b83-69ca-4bbc-d062-897812573374"
      },
      "source": [
        "accuracy(forest_tog, X_val, y_val.values)\n",
        "#accuracy(forest_sep, X_test, y_test.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8408833333333333\n",
            "0.8457333333333333\n",
            "0.8555333333333334\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEl2H-9Pf2oT"
      },
      "source": [
        "X_pred_tog = forest_tog.predict(X_test)\n",
        "X_pred_sep = forest_sep.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-quF7mP3KCBe",
        "outputId": "d2fac2a3-a316-494b-fcaf-c04b592ae665"
      },
      "source": [
        "compare([X_pred_sep[:, 0], X_pred_tog[:, 0]], y_test.values[:, 0].reshape(-1, 1))\n",
        "compare([X_pred_sep[:, 1], X_pred_tog[:, 1]], y_test.values[:, 1].reshape(-1, 1))\n",
        "compare([X_pred_sep[:, 2], X_pred_tog[:, 2]], y_test.values[:, 2].reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0.] \t 0.39413333333333334\n",
            "[0. 0. 1.] \t 0.05446666666666666\n",
            "[0. 1. 0.] \t 0.06145\n",
            "[0. 1. 1.] \t 0.06456666666666666\n",
            "[1. 0. 0.] \t 0.06663333333333334\n",
            "[1. 0. 1.] \t 0.061516666666666664\n",
            "[1. 1. 0.] \t 0.05333333333333334\n",
            "[1. 1. 1.] \t 0.2439\n",
            "\n",
            "[0. 0. 0.] \t 0.4023833333333333\n",
            "[0. 0. 1.] \t 0.05098333333333333\n",
            "[0. 1. 0.] \t 0.06055\n",
            "[0. 1. 1.] \t 0.06441666666666666\n",
            "[1. 0. 0.] \t 0.06695\n",
            "[1. 0. 1.] \t 0.059283333333333334\n",
            "[1. 1. 0.] \t 0.0519\n",
            "[1. 1. 1.] \t 0.24353333333333332\n",
            "\n",
            "[0. 0. 0.] \t 0.41385\n",
            "[0. 0. 1.] \t 0.053366666666666666\n",
            "[0. 1. 0.] \t 0.057666666666666665\n",
            "[0. 1. 1.] \t 0.07663333333333333\n",
            "[1. 0. 0.] \t 0.08095\n",
            "[1. 0. 1.] \t 0.054683333333333334\n",
            "[1. 1. 0.] \t 0.049183333333333336\n",
            "[1. 1. 1.] \t 0.21366666666666667\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEQdNj3DLvh-",
        "outputId": "16aa79f0-686c-4f56-b414-a2646cd206a3"
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "\n",
        "joblib.dump(forest_tog, path + \"forest_tog300.pk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/gdrive/MyDrive/ML/DataCrunch/models/forest_tog300.pk']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYIeY4VKnRp9"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2pyeHuNmW6z",
        "outputId": "acd021b8-c479-4b55-b93e-543f15add36e"
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "\n",
        "forest_tog = joblib.load(path + \"forest_tog300.pk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdRtjJK1yycv",
        "outputId": "fdeb6202-04bc-4120-df3e-46ea42bc0fba"
      },
      "source": [
        "for name, score in zip(X.columns, forest_tog.feature_importances_):#Freature selection\n",
        "  print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00047133919416389707\n",
            "0.0013503435086816952\n",
            "0.004213750042996247\n",
            "0.003771890153568458\n",
            "0.0028140695223395256\n",
            "0.0011280889718911938\n",
            "0.003055181453157459\n",
            "0.0033382767228269878\n",
            "0.0034550989205092194\n",
            "0.05901358296693257\n",
            "0.05924317386722408\n",
            "0.06585041182849721\n",
            "0.06906154494850429\n",
            "0.06135801995527331\n",
            "0.1471413958066277\n",
            "0.13096915001677092\n",
            "0.05815519173213166\n",
            "0.03900565553582767\n",
            "0.16036408577093336\n",
            "0.06333514185125165\n",
            "0.019219063697785026\n",
            "0.016578479520402922\n",
            "0.004425019395575224\n",
            "0.004222144514471291\n",
            "0.0011229245412461045\n",
            "0.0014459268525725726\n",
            "0.002565378662626692\n",
            "0.0011995391008096583\n",
            "0.0030187115077911983\n",
            "0.005100982209359026\n",
            "0.004006437227251175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXalwoJWMtkw"
      },
      "source": [
        "##Drop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea6X-a2nMxzL",
        "outputId": "db7d45a1-f329-4e85-f2e7-80aa83717b29"
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "\n",
        "\"\"\"Drop las features que no son importantes. Deberia generalizar mejor\"\"\"\n",
        "class ForestSep_drop(BaseEstimator, ClassifierMixin):#Que sean tres modelos SEParados no mejora nada\n",
        "  def __init__(self, bootstrap = False, n_estimators = 1000, max_features = \"auto\"):\n",
        "    self.forest_1 = RandomForestClassifier(bootstrap=bootstrap, max_features=max_features, n_estimators = n_estimators)\n",
        "    self.forest_2 = RandomForestClassifier(bootstrap=bootstrap, max_features=max_features, n_estimators = n_estimators)\n",
        "    self.forest_3 = RandomForestClassifier(bootstrap=bootstrap, max_features=max_features, n_estimators = n_estimators)\n",
        "  def fit(self, X, y):\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    self.forest_1.fit(X[:, 9:19], y[:, 0])\n",
        "    print(\"trained 1\")\n",
        "    self.forest_2.fit(X[:, 9:19], y[:, 1])\n",
        "    print(\"trained 2\")\n",
        "    self.forest_3.fit(X[:, 9:19], y[:, 2])\n",
        "    print(\"trained 3\")\n",
        "    return self\n",
        "  def predict(self, X):\n",
        "    X = np.asarray(X)\n",
        "    x = X[:, 9:19]\n",
        "    pred_1 = self.forest_1.predict(x).reshape(-1, 1)\n",
        "    pred_2 = self.forest_2.predict(x).reshape(-1, 1)\n",
        "    pred_3 = self.forest_3.predict(x).reshape(-1, 1)\n",
        "    return np.concatenate((pred_1, pred_2, pred_3), axis = 1)\n",
        "  def predict_proba(self, X):\n",
        "    X = np.asarray(X)\n",
        "    x = X[:, 9:19]\n",
        "    pred_1 = self.forest_1.predict_proba(X).reshape(-1, 1)\n",
        "    pred_2 = self.forest_2.predict_proba(X).reshape(-1, 1)\n",
        "    pred_3 = self.forest_3.predict_proba(X).reshape(-1, 1)\n",
        "    return np.concatenate((pred_1, pred_2, pred_3), axis = 1)\n",
        "  def set_params(self, **parameters):#necesario para el hyperparameter tunning\n",
        "    self.forest_1.set_params(**parameters)\n",
        "    self.forest_2.set_params(**parameters)\n",
        "    self.forest_3.set_params(**parameters)\n",
        "    return self\n",
        "  def get_params(self, deep=True):\n",
        "    return {\"bootstrap\": self.forest_1.get_params()['bootstrap'], \n",
        "             \"n_estimators\": self.forest_1.get_params()['n_estimators'],\n",
        "              \"max_features\": self.forest_1.get_params()['max_features']\n",
        "              }\n",
        "\n",
        "#forest_sep_drop = ForestSep_drop(n_estimators = 300, max_features = 6)\n",
        "\n",
        "t = time.time()\n",
        "#forest_sep_drop.fit(X_train, y_train.values)\n",
        "print(time.time() - t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.9087066650390625e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd4dfOT6wZFo",
        "outputId": "ba1d59b5-96fa-449a-d05a-7f41ccf4c0fd"
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "\n",
        "\"\"\"Drop las features que no son importantes. Deberia generalizar mejor\"\"\"\n",
        "class ForestTog_drop(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, bootstrap = False, n_estimators = 1000, max_features = 6):\n",
        "    self.forest = RandomForestClassifier(bootstrap=bootstrap, max_features=max_features, n_estimators = n_estimators)\n",
        "  def fit(self, X, y):\n",
        "    X = np.asarray(X)\n",
        "    x = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    #x = X[:, 9:19]\n",
        "    #print(x.shape)\n",
        "    y = np.asarray(y)\n",
        "    self.forest.fit(x, y)\n",
        "    return self\n",
        "  def predict(self, X):\n",
        "    X = np.asarray(X)\n",
        "    x = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    #x = X[:, 9:19]\n",
        "    return self.forest.predict(x)\n",
        "  def predict_proba(self, X):\n",
        "    X = np.asarray(X)\n",
        "    x = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    #x = X[:, 9:19]\n",
        "    return self.forest.predict_proba(x)\n",
        "  def set_params(self, **parameters):\n",
        "    self.forest.set_params(**parameters)\n",
        "    return self\n",
        "  def get_params(self, deep=True):\n",
        "    return {\"bootstrap\": self.forest.get_params()['bootstrap'], \n",
        "             \"n_estimators\": self.forest.get_params()['n_estimators'],\n",
        "              \"max_features\": self.forest.get_params()['max_features']\n",
        "              }\n",
        "\n",
        "#forest_tog_drop = ForestTog_drop(n_estimators = 300, max_features = 6)\n",
        "\n",
        "t = time.time()\n",
        "#forest_tog_drop.fit(X_train, y_train.values)\n",
        "print(time.time() - t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5033950805664062e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4r2itcjZhSu",
        "outputId": "92d6e7c4-c90d-40e0-f53e-31e9ec922d07"
      },
      "source": [
        "accuracy(forest_tog_drop, X_test, y_test.values)\n",
        "#accuracy(forest_sep_drop, X_test, y_test.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8228666666666666\n",
            "0.83105\n",
            "0.8415\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDRtQA-3aKKL",
        "outputId": "5af1a6f8-e2c5-44a5-807f-8c0dc2818167"
      },
      "source": [
        "\"\"\"Comparar sep y tog\"\"\"\n",
        "X_pred_tog_drop = forest_tog_drop.predict(X_test)\n",
        "X_pred_sep_drop = forest_sep_drop.predict(X_test)\n",
        "\n",
        "compare([X_pred_tog_drop[:, 0], X_pred_sep_drop[:, 0]], y_test.values[:, 0].reshape(-1, 1))\n",
        "compare([X_pred_tog_drop[:, 1], X_pred_sep_drop[:, 1]], y_test.values[:, 1].reshape(-1, 1))\n",
        "compare([X_pred_tog_drop[:, 2], X_pred_sep_drop[:, 2]], y_test.values[:, 2].reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0.] \t 0.46776666666666666\n",
            "[0. 0. 1.] \t 0.0651\n",
            "[0. 1. 0.] \t 0.0258\n",
            "[0. 1. 1.] \t 0.024166666666666666\n",
            "[1. 0. 0.] \t 0.023183333333333334\n",
            "[1. 0. 1.] \t 0.03055\n",
            "[1. 1. 0.] \t 0.0588\n",
            "[1. 1. 1.] \t 0.3046333333333333\n",
            "\n",
            "[0. 0. 0.] \t 0.47886666666666666\n",
            "[0. 0. 1.] \t 0.06451666666666667\n",
            "[0. 1. 0.] \t 0.025\n",
            "[0. 1. 1.] \t 0.021466666666666665\n",
            "[1. 0. 0.] \t 0.020683333333333335\n",
            "[1. 0. 1.] \t 0.029383333333333334\n",
            "[1. 1. 0.] \t 0.05723333333333333\n",
            "[1. 1. 1.] \t 0.30285\n",
            "\n",
            "[0. 0. 0.] \t 0.5081\n",
            "[0. 0. 1.] \t 0.07068333333333333\n",
            "[0. 1. 0.] \t 0.020216666666666668\n",
            "[0. 1. 1.] \t 0.023983333333333332\n",
            "[1. 0. 0.] \t 0.019\n",
            "[1. 0. 1.] \t 0.021433333333333332\n",
            "[1. 1. 0.] \t 0.05433333333333333\n",
            "[1. 1. 1.] \t 0.28225\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Xg6O9SZG5Uo",
        "outputId": "f493e127-038a-4066-f5ec-6c4a9077ec53"
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "\n",
        "joblib.dump(forest_tog_drop, path + \"forest_tog_drop300.pk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/gdrive/MyDrive/ML/DataCrunch/models/forest_tog_drop300.pk']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV_wvy_GL4gv"
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "\n",
        "forest_tog_drop = joblib.load(path + \"forest_tog_drop300.pk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrBBWt5CpCe6"
      },
      "source": [
        "##PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aggFQ4vLpEwl",
        "outputId": "dea6ee96-ec96-4884-c221-d4ba142eca97"
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\"\"\"Drop de las features no importantes y PCA. El n_componenents es un hiperparametro\"\"\"\n",
        "class ForestTog_pca(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, bootstrap = False, n_estimators = 10, max_features = 6, n_components = 11, max_depth = None):\n",
        "    self.forest = RandomForestClassifier(bootstrap=bootstrap, max_features=max_features, n_estimators = n_estimators, max_depth = max_depth)\n",
        "    self.pca = PCA(n_components = n_components)\n",
        "    #print(\"created\")\n",
        "  def fit(self, X, y):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    #print(\"start pca\")\n",
        "    X = self.pca.fit_transform(X)\n",
        "    #print(\"pca done\")\n",
        "    y = np.asarray(y)\n",
        "    self.forest.fit(X, y)\n",
        "    #print(\"forest trained\")\n",
        "    print(\"trained\")\n",
        "    return self\n",
        "  def predict(self, X):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    X = self.pca.transform(X)\n",
        "    return self.forest.predict(X)\n",
        "  def predict_proba(self, X):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    X = self.pca.transform(X)\n",
        "    return self.forest.predict_proba(X)\n",
        "  def set_params(self, **parameters):\n",
        "    self.forest.set_params(**parameters)\n",
        "    #self.pca.set_params(**parameters)\n",
        "    return self\n",
        "  def get_params(self, deep=True):\n",
        "    return {\"bootstrap\": self.forest.get_params()['bootstrap'], \n",
        "            \"n_estimators\": self.forest.get_params()['n_estimators'],\n",
        "            \"max_features\": self.forest.get_params()['max_features'],\n",
        "            \"n_components\": self.pca.get_params()[\"n_components\"]\n",
        "            }\n",
        "\n",
        "forest_tog_pca = ForestTog_pca(n_estimators = 100, max_features = 6, n_components = 11)\n",
        "\n",
        "t = time.time()\n",
        "#forest_tog_pca.fit(X_train, y_train.values)\n",
        "print(time.time() - t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4557113647460938e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3T79aV_ZXXG",
        "outputId": "aed18080-5231-458d-dc20-114e8c9c1a5c"
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\"\"\"Igual, pero concatena el PCA y la features normales, parece no mejorar nada\"\"\"\n",
        "class ForestTog_pcap(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, bootstrap = False, n_estimators = 10, max_features = 6, n_components = 11, max_depth = None):\n",
        "    self.forest = RandomForestClassifier(bootstrap=bootstrap, max_features=max_features, n_estimators = n_estimators, max_depth = max_depth)\n",
        "    self.pca = PCA(n_components = n_components)\n",
        "  def fit(self, X, y):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    X = np.concatenate((X,self.pca.fit_transform(X)), axis = 1)\n",
        "    y = np.asarray(y)\n",
        "    self.forest.fit(X, y)\n",
        "    print(\"trained\")\n",
        "    return self\n",
        "  def predict(self, X):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    X = np.concatenate((X,self.pca.transform(X)), axis = 1)\n",
        "    return self.forest.predict(X)\n",
        "  def predict_proba(self, X):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    X = np.concatenate((X,self.pca.transform(X)), axis = 1)\n",
        "    return self.forest.predict_proba(X)\n",
        "  def set_params(self, **parameters):\n",
        "    self.forest.set_params(**parameters)\n",
        "    #self.pca.set_params(**parameters)\n",
        "    return self\n",
        "  def get_params(self, deep=True):\n",
        "    return {\"bootstrap\": self.forest.get_params()['bootstrap'], \n",
        "            \"n_estimators\": self.forest.get_params()['n_estimators'],\n",
        "            \"max_features\": self.forest.get_params()['max_features'],\n",
        "            \"n_components\": self.pca.get_params()[\"n_components\"]\n",
        "            }\n",
        "\n",
        "forest_tog_pcap = ForestTog_pcap(n_estimators = 100, max_features = 20, n_components = 11)\n",
        "\n",
        "t = time.time()\n",
        "#forest_tog_pcap.fit(X_train, y_train.values)\n",
        "print(time.time() - t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.790855407714844e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gEziQbJrEye",
        "outputId": "300431be-58ba-4db5-c9c8-d952b1ad68eb"
      },
      "source": [
        "accuracy(forest_tog_pcap, X_test, y_test.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7727333333333334\n",
            "0.7812\n",
            "0.7949166666666667\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMAvpnWfrIq6",
        "outputId": "15d912ae-11b9-4e3b-8d9e-35c01d9d3628"
      },
      "source": [
        "X_pred_tog_pcab = forest_tog_pca.predict(X_test)\n",
        "X_pred_sep_pca = S_forest_tog_pca300.predict(X_test)\n",
        "\n",
        "compare([X_pred_tog_pcab[:, 0], X_pred_sep_pca[:, 0]], y_test.values[:, 0].reshape(-1, 1))\n",
        "compare([X_pred_tog_pcab[:, 1], X_pred_sep_pca[:, 1]], y_test.values[:, 1].reshape(-1, 1))\n",
        "compare([X_pred_tog_pcab[:, 2], X_pred_sep_pca[:, 2]], y_test.values[:, 2].reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0.] \t 0.44503333333333334\n",
            "[0. 0. 1.] \t 0.13383333333333333\n",
            "[0. 1. 0.] \t 0.011416666666666667\n",
            "[0. 1. 1.] \t 0.010983333333333333\n",
            "[1. 0. 0.] \t 0.01055\n",
            "[1. 0. 1.] \t 0.011233333333333333\n",
            "[1. 1. 0.] \t 0.10855\n",
            "[1. 1. 1.] \t 0.2684\n",
            "\n",
            "[0. 0. 0.] \t 0.46058333333333334\n",
            "[0. 0. 1.] \t 0.13068333333333335\n",
            "[0. 1. 0.] \t 0.01025\n",
            "[0. 1. 1.] \t 0.010416666666666666\n",
            "[1. 0. 0.] \t 0.00995\n",
            "[1. 0. 1.] \t 0.010933333333333333\n",
            "[1. 1. 0.] \t 0.101\n",
            "[1. 1. 1.] \t 0.2661833333333333\n",
            "\n",
            "[0. 0. 0.] \t 0.4975333333333333\n",
            "[0. 0. 1.] \t 0.13308333333333333\n",
            "[0. 1. 0.] \t 0.009366666666666667\n",
            "[0. 1. 1.] \t 0.009683333333333334\n",
            "[1. 0. 0.] \t 0.0093\n",
            "[1. 0. 1.] \t 0.0096\n",
            "[1. 1. 0.] \t 0.08545\n",
            "[1. 1. 1.] \t 0.24598333333333333\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6mfRZRnP0cs",
        "outputId": "ccfb6926-f40b-4792-aeaf-a7ba37934f1e"
      },
      "source": [
        "for name, score in zip(X.columns, forest_tog_pcap.forest.feature_importances_):\n",
        "  print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.027203381767329293\n",
            "0.037542238839031634\n",
            "0.03058797508406875\n",
            "0.03288268162441428\n",
            "0.027509721110265076\n",
            "0.07670309623139847\n",
            "0.08712393056786084\n",
            "0.024075400492603878\n",
            "0.015666435388998624\n",
            "0.1260945880862815\n",
            "0.0013076499196809637\n",
            "0.04269325319475436\n",
            "0.05148517115332211\n",
            "0.031172652594143566\n",
            "0.03784576756443117\n",
            "0.04104699738131596\n",
            "0.06124677701283131\n",
            "0.04180570289880477\n",
            "0.05440194320656051\n",
            "0.05671548224140764\n",
            "0.04608728226104742\n",
            "0.04880187137944784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACq5hqv25NZ7",
        "outputId": "af07d577-c03e-4989-f871-8ac209e0dbb7"
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "\n",
        "joblib.dump(forest_tog_pcap, path + \"models/\" + \"forest_join300.pk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/gdrive/MyDrive/ML/DataCrunch/models/forest_join300.pk']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR7oxXpO5Bk_"
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "\n",
        "forest_tog_pca = joblib.load(path + \"models/\" + \"forest_tog_pca300.pk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09088pONZ-oU"
      },
      "source": [
        "##hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjCP5CCnWsY-"
      },
      "source": [
        "forest_tog_pcap = ForestTog_pcap(n_estimators = 10, max_features = 16, n_components = 11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxahx7Gfo2Xh"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "              {'n_estimators': [10], \"max_features\": [10, 11, 12, 13, 14, 15, 16, 17]}\n",
        "]\n",
        "\n",
        "grid_search = GridSearchCV(forest_tog_pcap, param_grid, cv = 3, scoring = 'accuracy', refit = False)#ir cambiando el modelo\n",
        "\n",
        "grid_search.fit(X_d, y_d.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QK_QIPwi3lGN",
        "outputId": "95229280-2a6d-41de-c7b6-a0f87faa42cb"
      },
      "source": [
        "cvres = grid_search.cv_results_\n",
        "for score, std, time, param in zip(cvres[\"mean_test_score\"],cvres[\"std_test_score\"] ,cvres[\"mean_fit_time\"], cvres[\"params\"]):\n",
        "  print(param, \"\\t\", score, \"\\t\", std ,\"\\t\", time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'max_features': 10, 'n_estimators': 10} \t 0.5902333333333334 \t 0.009450718300155259 \t 46.69732133547465\n",
            "{'max_features': 11, 'n_estimators': 10} \t 0.5890208333333334 \t 0.005440361635242804 \t 50.902156035105385\n",
            "{'max_features': 12, 'n_estimators': 10} \t 0.5927916666666667 \t 0.004166662499997938 \t 54.06312823295593\n",
            "{'max_features': 13, 'n_estimators': 10} \t 0.5903125 \t 0.002630767473571188 \t 59.18082666397095\n",
            "{'max_features': 14, 'n_estimators': 10} \t 0.5909833333333333 \t 0.005112131540648066 \t 62.02290280659994\n",
            "{'max_features': 15, 'n_estimators': 10} \t 0.5907458333333334 \t 0.0025175288258308037 \t 66.31953692436218\n",
            "{'max_features': 16, 'n_estimators': 10} \t 0.5934 \t 0.006468384651518472 \t 69.29738473892212\n",
            "{'max_features': 17, 'n_estimators': 10} \t 0.590825 \t 0.0011844038584874388 \t 74.35504841804504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DJQZ_E0fqNl",
        "outputId": "84c59fc4-e1ff-44d0-f48b-8f0898de43dc"
      },
      "source": [
        "grid_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ForestSep_drop(bootstrap=None, max_features=None, n_estimators=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3uWBdViYJsr"
      },
      "source": [
        "forest=RandomForestClassifier(bootstrap=False,\n",
        "                              max_depth=None,\n",
        "                              max_features=20,\n",
        "                              max_leaf_nodes=None,\n",
        "                              max_samples=None,\n",
        "                              n_estimators=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6vDzWuEbAbr"
      },
      "source": [
        "#Extra Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1iIMCTLbEI1",
        "outputId": "36e9cff7-64cb-4629-a140-e789d23c8d00"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "extraForest = ExtraTreesClassifier(n_estimators = 150)\n",
        "\n",
        "extraForest.fit(X_train , y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
              "                     criterion='gini', max_depth=None, max_features='auto',\n",
              "                     max_leaf_nodes=None, max_samples=None,\n",
              "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                     min_samples_leaf=1, min_samples_split=2,\n",
              "                     min_weight_fraction_leaf=0.0, n_estimators=150,\n",
              "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
              "                     warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmdHzVZSbhj4",
        "outputId": "455b4551-08a5-4285-a74b-43ca1abe783b"
      },
      "source": [
        "accuracy(extraForest, X_test, y_test.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7323666666666667\n",
            "0.7402166666666666\n",
            "0.7565\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PErG2Ox0fuc2"
      },
      "source": [
        "S_extrab = smodel(\"extra150b\")\n",
        "S_extrab.loadModel(model = extraForest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXxck7GJiP4j"
      },
      "source": [
        "del(extraForest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw1l15DghQ0Q"
      },
      "source": [
        "#Ada boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nQBSlrehS81",
        "outputId": "a4397268-985b-48c2-816f-9a25a8c6b1f8"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import time\n",
        "\n",
        "ada = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_leaf_nodes=200), n_estimators=500,\n",
        "    algorithm=\"SAMME.R\", learning_rate=0.5\n",
        "    )\n",
        "\n",
        "t = time.time()\n",
        "ada.fit(X_train, y_train.values[:, 0])\n",
        "print(time.time() - t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1338.385749578476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVh9hBgC5BZX",
        "outputId": "712beda1-a7cd-49fe-eb51-01c7fe421a23"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import time\n",
        "\n",
        "class adaSep(BaseEstimator, ClassifierMixin): #tienen que ser tres modelos separados\n",
        "  def __init__(self, n_estimators = 1500):\n",
        "    self.model1 = AdaBoostClassifier(\n",
        "                                  DecisionTreeClassifier(max_leaf_nodes=200), n_estimators=n_estimators,\n",
        "                                  algorithm=\"SAMME.R\", learning_rate=0.5\n",
        "                                  )\n",
        "    self.model2 = AdaBoostClassifier(\n",
        "                                  DecisionTreeClassifier(max_leaf_nodes=200), n_estimators=n_estimators,\n",
        "                                  algorithm=\"SAMME.R\", learning_rate=0.5\n",
        "                                  )\n",
        "    self.model3 = AdaBoostClassifier(\n",
        "                                  DecisionTreeClassifier(max_leaf_nodes=200), n_estimators=n_estimators,\n",
        "                                  algorithm=\"SAMME.R\", learning_rate=0.5\n",
        "                                  )\n",
        "  def fit(self, X, y):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    y = np.asarray(y)\n",
        "    self.model1.fit(X, y[:, 0])\n",
        "    print(\"trained 1\")\n",
        "    self.model2.fit(X, y[:, 1])\n",
        "    print(\"trained 2\")\n",
        "    self.model3.fit(X, y[:, 2])\n",
        "    print(\"trained 3\")\n",
        "  def predict(self, X):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    pred_1 = self.model1.predict(X).reshape(-1, 1)\n",
        "    pred_2 = self.model2.predict(X).reshape(-1, 1)\n",
        "    pred_3 = self.model3.predict(X).reshape(-1, 1)\n",
        "    return np.concatenate((pred_1, pred_2, pred_3), axis = 1)\n",
        "  def predict_proba(self, X):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    pred_1 = self.model1.predict_proba(X).reshape(-1, 2)\n",
        "    pred_2 = self.model2.predict_proba(X).reshape(-1, 2)\n",
        "    pred_3 = self.model3.predict_proba(X).reshape(-1, 2)\n",
        "    return [pred_1, pred_2, pred_3]\n",
        "\n",
        "#ada = adaSep(n_estimators = 600)\n",
        "\n",
        "t = time.time()\n",
        "#ada.fit(X_train, y_train.values)\n",
        "print(time.time() - t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.886222839355469e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt6YtOPyhtsX"
      },
      "source": [
        "accuracy(S_ada1, X_test, y_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6Pbw08jol_Q",
        "outputId": "6bd62527-3e21-4cda-c140-915e3b70a2e8"
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "\n",
        "joblib.dump(ada, path + \"models/\" + \"ada200_600.pk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/gdrive/MyDrive/ML/DataCrunch/models/ada200_600.pk']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydw5OonvZoAe"
      },
      "source": [
        "S_ada1 = smodel(\"ada20_1500\")\n",
        "S_ada1.loadModel(model = ada)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-qwi43StVSn"
      },
      "source": [
        "S_ada2 = smodel(\"ada200_600\")\n",
        "S_ada2.loadModel(model = ada)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4PdzFuuh69Q"
      },
      "source": [
        "#gradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf9Alhlyh9dX",
        "outputId": "669b54e0-9c7b-43f8-91a0-3a6dea84fbd9"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gdrt = GradientBoostingRegressor(max_depth = 20, n_estimators = 30, learning_rate = 1)\n",
        "\n",
        "gdrt.fit(X_train, y_train.values[:,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
              "                          init=None, learning_rate=1, loss='ls', max_depth=20,\n",
              "                          max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=30,\n",
              "                          n_iter_no_change=None, presort='deprecated',\n",
              "                          random_state=None, subsample=1.0, tol=0.0001,\n",
              "                          validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwzdFC4Ejit1",
        "outputId": "99e68c4d-be5b-4f8a-9d82-2a958f41d949"
      },
      "source": [
        "accuracy(gdrt, X_test, y_test.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9983888888888889\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cTexIWv3gcC"
      },
      "source": [
        "#Neighbourds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKG9A_K1M0go"
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.neighbors  import KNeighborsClassifier\n",
        "\n",
        "import time\n",
        "\n",
        "class Neigh(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, n_neighbors=3):\n",
        "    self.model = KNeighborsClassifier(n_neighbors = n_neighbors, weights = \"distance\")\n",
        "  def fit(self, X, y):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    y = np.asarray(y)\n",
        "    self.model.fit(X, y)\n",
        "  def predict(self, X):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    return self.model.predict(X)\n",
        "  def predict_proba(self, X):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    return self.model.predict_proba(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HB3a_4h5B2p"
      },
      "source": [
        "from sklearn.neighbors  import KNeighborsClassifier\n",
        "\n",
        "neigh = Neigh(n_neighbors=40)\n",
        "neigh.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3BVHK8TMiEp",
        "outputId": "a42e81e3-6c70-4ef4-bc21-eb38c5209c8b"
      },
      "source": [
        "accuracy(neigh, X_test, y_test.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6676666666666666\n",
            "0.6762833333333333\n",
            "0.6933\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tT_Ih0OsPCq"
      },
      "source": [
        "#Model **Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS41TasssdTG"
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "\"\"\"\n",
        "Para poder manejar tantos model juntos a la vez  he creado esta clase\n",
        "Guarda en archivos las predicciones y los modelos\n",
        "Entonces no hay que tener el modelo en ram para hacer las predicciones asi que se puden tener todos operativos\n",
        "y hace las predicciones instantaneamente, ya que estan hechas de antemano\n",
        "\n",
        "Meneja guardar y cargar los modelos de una manera bastante comoda. Puede usar un modelo, o el archivo deonde esta guardado el modelo\n",
        "\n",
        "El plan era combinar los modelos de algina manera, pero encontre dificultades con eso\n",
        "\"\"\"\n",
        "class smodel(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, name, load_from_file = False):\n",
        "    self.model = None\n",
        "    self.y_pred_train = None\n",
        "    self.y_pred_test = None\n",
        "    self.y_pred_val = None\n",
        "    self.name = name\n",
        "    if(load_from_file):\n",
        "      self.loadFile()\n",
        "    pass\n",
        "  def loadModel(self, model = None):\n",
        "    if (model == None):\n",
        "      self.model = joblib.load(path + \"models/\" + self.name + \".pk\")\n",
        "    else:\n",
        "      self.model = model\n",
        "      joblib.dump(self.model, path + \"models/\" + self.name + \".pk\")\n",
        "\n",
        "    self.y_pred_train = self.model.predict_proba(X_train)\n",
        "    #if len(self.y_pred_train.shape) < 3:\n",
        "    #  self.y_pred_train = np.expand_dims(self.y_pred_train, axis = -1)\n",
        "      #print(self.y_pred_train.shape)\n",
        "      #self.y_pred_train = np.concatenate((1- self.y_pred_train, self.y_pred_train),axis = -1)\n",
        "    \n",
        "    self.y_pred_test = self.model.predict_proba(X_test)\n",
        "    #if len(self.y_pred_test.shape) < 3:\n",
        "     # self.y_pred_test = np.expand_dims(self.y_pred_test, axis = -1)\n",
        "      #self.y_pred_test = np.concatenate((1- self.y_pred_test, self.y_pred_test),axis = -1)\n",
        "    \n",
        "    self.y_pred_val = self.model.predict_proba(X_val)\n",
        "    #if len(self.y_pred_val.shape) < 3:      \n",
        "     # self.y_pred_val = np.expand_dims(self.y_pred_val, axis = -1)\n",
        "      #self.y_pred_val = np.concatenate((1- self.y_pred_val, self.y_pred_val),axis = -1)\n",
        "    del(self.model)\n",
        "    self.save2File()\n",
        "  def save2File(self):\n",
        "    np.save(path + \"preds/\" + self.name + \"_train\" + \".npy\", self.y_pred_train)\n",
        "    np.save(path + \"preds/\" + self.name + \"_test\" + \".npy\", self.y_pred_test)\n",
        "    np.save(path + \"preds/\" + self.name + \"_val\" + \".npy\", self.y_pred_val)\n",
        "  def loadFile(self):\n",
        "    self.y_pred_train = np.load(path + \"preds/\" + self.name + \"_train\" + \".npy\")\n",
        "    self.y_pred_test = np.load(path + \"preds/\" + self.name + \"_test\" + \".npy\")\n",
        "    self.y_pred_val = np.load(path + \"preds/\" + self.name + \"_val\" + \".npy\")\n",
        "  def fit(self, X, y):\n",
        "    return self\n",
        "  def predict(self, X):\n",
        "    X = X.values\n",
        "    self.loadFile()\n",
        "   # if(self.y_pred_test == None):\n",
        "    #  self.leadFile()\n",
        "    if((X[0]==X_train.values[0]).all()):\n",
        "      return (np.asarray(self.y_pred_train)[:, :, 1] > 0.5).astype(int).transpose()\n",
        "    if((X[0]==X_test.values[0]).all()):\n",
        "      return (np.asarray(self.y_pred_test)[:, :, 1] > 0.5).astype(int).transpose()\n",
        "    if((X[0]==X_val.values[0]).all()):\n",
        "      return (np.asarray(self.y_pred_val)[:, :, 1] > 0.5).astype(int).transpose()\n",
        "  def predict_proba(self, X):\n",
        "    X = X.values\n",
        "    self.loadFile()\n",
        "    if((X[0]==X_train.values[0]).all()):\n",
        "      return self.y_pred_train\n",
        "    if((X[0]==X_test.values[0]).all()):\n",
        "      return self.y_pred_test\n",
        "    if((X[0]==X_val.values[0]).all()):\n",
        "      return self.y_pred_val\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmeZHk3FZIKN"
      },
      "source": [
        "S_forest = smodel(\"forest300\", load_from_file=True)\n",
        "S_forest_drop = smodel(\"forest_drop300\", load_from_file=True)\n",
        "S_forest_pca = smodel(\"forest_pca300\", load_from_file=True)\n",
        "S_forest_pcab = smodel(\"forest_pca300b\", load_from_file=True)\n",
        "S_forest_join = smodel(\"forest_join300\", load_from_file=True)\n",
        "S_extra = smodel(\"extra150\", load_from_file=True)\n",
        "S_extrab = smodel(\"extra150b\", load_from_file=True)\n",
        "S_neigh = smodel(\"neigh40\", load_from_file=True)\n",
        "S_ada1 = smodel(\"ada20_1500\", load_from_file=True)\n",
        "#S_ada2 = smodel(\"ada200_600\", load_from_file=True)\n",
        "#S_xgb = smodel(\"xgb20_6000\", load_from_file=True)\n",
        "\n",
        "list_models = [S_forest, S_forest_drop, S_forest_join, S_ada1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytsaSb-UaiRQ"
      },
      "source": [
        "S_forest_drop = smodel(\"forest_drop300\")\n",
        "S_forest_drop.loadModel() ##cargar modelo del archivo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZLb_BoTh9g5"
      },
      "source": [
        "S_neigh = smodel(\"neigh40\")\n",
        "S_neigh.loadModel(model = neigh) ##usar el modelo nigh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPY4AjstgCpA"
      },
      "source": [
        "S_ada1 = smodel(\"ada20_1500\")\n",
        "S_ada1.loadModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8stv23ydlkMk"
      },
      "source": [
        "accuracy(S_ada1, X_test, y_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5kodSmkX49v"
      },
      "source": [
        "compareModel(S_forest_pca, S_xgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFmOXJJYevdg"
      },
      "source": [
        "#xgboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPT5U80yo8OE",
        "outputId": "46213d08-716b-4677-c0fa-6e6613da67db"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "import time\n",
        "\n",
        "class XGB(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, n_estimators = 1000):\n",
        "    self.model1 = XGBClassifier(max_depth=20, learning_rate=0.01, n_estimators=n_estimators, colsample_bytree=0.1)\n",
        "    self.model2 = XGBClassifier(max_depth=20, learning_rate=0.01, n_estimators=n_estimators, colsample_bytree=0.1)\n",
        "    self.model3 = XGBClassifier(max_depth=20, learning_rate=0.01, n_estimators=n_estimators, colsample_bytree=0.1)\n",
        "  def fit(self, X, y):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    y = np.asarray(y)\n",
        "    self.model1.fit(X, y[:, 0])\n",
        "    print(\"trained 1\")\n",
        "    self.model2.fit(X, y[:, 1])\n",
        "    print(\"trained 2\")\n",
        "    self.model3.fit(X, y[:, 2])\n",
        "    print(\"trained 3\")\n",
        "  def predict(self, X):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    pred_1 = self.model1.predict(X).reshape(-1, 1)\n",
        "    pred_2 = self.model2.predict(X).reshape(-1, 1)\n",
        "    pred_3 = self.model3.predict(X).reshape(-1, 1)\n",
        "    return np.concatenate((pred_1, pred_2, pred_3), axis = 1)\n",
        "  def predict_proba(self, X):\n",
        "    X = np.asarray(X)\n",
        "    X = np.concatenate((X[:, 9:19], X[:, 30].reshape(-1, 1)), axis = 1)\n",
        "    pred_1 = self.model1.predict_proba(X).reshape(-1, 2)\n",
        "    pred_2 = self.model2.predict_proba(X).reshape(-1, 2)\n",
        "    pred_3 = self.model3.predict_proba(X).reshape(-1, 2)\n",
        "    return [pred_1, pred_2, pred_3]\n",
        "\n",
        "xgb = XGB(n_estimators = 10)\n",
        "\n",
        "t = time.time()\n",
        "xgb.fit(X_train, y_train.values)\n",
        "print(time.time() - t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trained 1\n",
            "trained 2\n",
            "trained 3\n",
            "5.315197229385376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFWW7ZaBfA9h",
        "outputId": "9b2f06b3-2685-413a-9224-b75d91f9749c"
      },
      "source": [
        "accuracy(xgb, X_test, y_test.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6253333333333333\n",
            "0.6314333333333333\n",
            "0.62255\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bqv4tM9rURY"
      },
      "source": [
        "S_xgb = smodel(\"xgbborrar\")\n",
        "S_xgb.loadModel(model = forest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh-OElmoTGV9",
        "outputId": "91bf191d-dad2-4c8d-bd3e-7eb2c2bfbfa5"
      },
      "source": [
        "xgb.predict_proba(X_test).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 2, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_x5NsozTj3F",
        "outputId": "1f76905d-1648-4ed4-f1eb-fd5d84aa2985"
      },
      "source": [
        "S_forest_pca.predict_proba(X_test).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 60000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEd25pF8T3vb",
        "outputId": "49bde633-55da-4120-f4ee-98b8f4b510b6"
      },
      "source": [
        "forest = RandomForestClassifier(n_estimators = 4)\n",
        "forest.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=4,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLB5zzWsUNjG",
        "outputId": "3e63b4b2-58f9-4810-f776-3a8e58627152"
      },
      "source": [
        "forest.predict_proba(X_test)[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gKRiCsOQzrG"
      },
      "source": [
        "S_ada1 = smodel(\"ada20_1500\")\n",
        "S_ada1.loadModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd8j3KiOL0I",
        "outputId": "45f19162-ca7f-4919-c2df-42f97b8d5f9e"
      },
      "source": [
        "S_ada1.y_pred_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5126546 , 0.515769  , 0.5167023 ],\n",
              "       [0.4873454 , 0.48423102, 0.4832977 ],\n",
              "       [0.50999486, 0.5100281 , 0.49830198],\n",
              "       ...,\n",
              "       [0.48454925, 0.4831524 , 0.48364112],\n",
              "       [0.49811202, 0.49936587, 0.51253474],\n",
              "       [0.501888  , 0.50063413, 0.48746523]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUvMXlHmcFgY"
      },
      "source": [
        "#Compare all the models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzqH1NGdcJ4J",
        "outputId": "79b377ef-690b-4099-a241-6e1d24592284"
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "stats.spearmanr(S_extra.predict(X_test)[:, 0], S_extrab.predict(X_test)[:, 0])[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8573059117009949"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c2CZPjPe7Hd",
        "outputId": "fb46c096-b839-4480-d07c-b12be71b8e5c"
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "for model1 in list_models:\n",
        "  for model2 in list_models:\n",
        "    stat = 0\n",
        "    for i in range(3):\n",
        "      stat += stats.spearmanr(model1.predict(X_test)[:, 0], model2.predict(X_test)[:, 0])[0]\n",
        "    print(stat/3 , end = \"\\t\")\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\t0.8225459286698866\t0.553902950765111\t0.736014262486994\t0.5511828798038776\t0.5865488020438108\t0.3911569732077113\t\n",
            "0.8225459286698866\t1.0\t0.5754493752992056\t0.7776381830556712\t0.531995044184726\t0.579968837668071\t0.4069015390661946\t\n",
            "0.553902950765111\t0.5754493752992056\t1.0\t0.6730717107911391\t0.5385969007453659\t0.42693765170837983\t0.529571880797586\t\n",
            "0.7360142624869942\t0.7776381830556712\t0.6730717107911391\t0.9999999999999999\t0.5414962914316352\t0.5363905458801111\t0.45021938803433875\t\n",
            "0.5511828798038777\t0.531995044184726\t0.5385969007453659\t0.5414962914316354\t1.0\t0.4172853330309541\t0.4403166924598725\t\n",
            "0.5865488020438107\t0.5799688376680711\t0.42693765170837983\t0.5363905458801111\t0.4172853330309541\t1.0\t0.32368952614554874\t\n",
            "0.39115697320771137\t0.4069015390661946\t0.529571880797586\t0.4502193880343388\t0.44031669245987254\t0.32368952614554874\t1.0\t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx7FX3TggJlP",
        "outputId": "626596c2-5f92-4ae8-9c27-044f3cf95bbc"
      },
      "source": [
        "for model in list_models:\n",
        "  print(model.name)\n",
        "  accuracy(model, X_test, y_test.values)\n",
        "  accuracy(model, X_val, y_val.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "forest300\n",
            "0.8382\n",
            "0.8458166666666667\n",
            "0.8534333333333334\n",
            "\n",
            "0.8408833333333333\n",
            "0.8457333333333333\n",
            "0.8555333333333334\n",
            "\n",
            "forest_drop300\n",
            "0.8228666666666666\n",
            "0.83105\n",
            "0.8415\n",
            "\n",
            "0.8264333333333334\n",
            "0.8319166666666666\n",
            "0.8410666666666666\n",
            "\n",
            "forest_pca300\n",
            "0.7349666666666667\n",
            "0.7471333333333333\n",
            "0.7625\n",
            "\n",
            "0.7382833333333333\n",
            "0.7437166666666667\n",
            "0.7638833333333334\n",
            "\n",
            "forest_join300\n",
            "0.7996666666666666\n",
            "0.8078666666666666\n",
            "0.81885\n",
            "\n",
            "0.8017833333333333\n",
            "0.80765\n",
            "0.8180333333333333\n",
            "\n",
            "extra150\n",
            "0.7323666666666667\n",
            "0.7402166666666666\n",
            "0.7565\n",
            "\n",
            "0.7293\n",
            "0.7389666666666667\n",
            "0.7588333333333334\n",
            "\n",
            "ada20_1500\n",
            "0.7889333333333334\n",
            "0.7936833333333333\n",
            "0.8078333333333333\n",
            "\n",
            "0.7896333333333333\n",
            "0.7974833333333333\n",
            "0.8086333333333333\n",
            "\n",
            "neigh40\n",
            "0.6676666666666666\n",
            "0.6762833333333333\n",
            "0.6933\n",
            "\n",
            "0.6677166666666666\n",
            "0.67635\n",
            "0.69175\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp8Na2Zmo3s4",
        "outputId": "8e5d8bcd-56c9-45ba-c465-6f79d7ab3b06"
      },
      "source": [
        "a = np.zeros_like(y_test.values).astype(float)\n",
        "for model in list_models:\n",
        "  a += np.asarray(model.predict(X_test))\n",
        "  print(model.name)\n",
        "a = a/len(list_models)\n",
        "a = (a > 0.5).astype(int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "forest300\n",
            "forest_drop300\n",
            "forest_join300\n",
            "ada20_1500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RswYI0D8pqGr",
        "outputId": "cb12e740-989c-4d12-d579-870bcf4a9422"
      },
      "source": [
        "  compare([a[:, 0], y_test.values[:, 0]], y_test.values[:, 0].reshape(-1, 1))\n",
        "  compare([a[:, 1], y_test.values[:, 1]], y_test.values[:, 1].reshape(-1, 1))\n",
        "  compare([a[:, 2], y_test.values[:, 2]], y_test.values[:, 2].reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0.] \t 0.50915\n",
            "[0. 0. 1.] \t 0.0\n",
            "[0. 1. 0.] \t 0.0\n",
            "[0. 1. 1.] \t 0.10398333333333333\n",
            "[1. 0. 0.] \t 0.0664\n",
            "[1. 0. 1.] \t 0.0\n",
            "[1. 1. 0.] \t 0.0\n",
            "[1. 1. 1.] \t 0.3204666666666667\n",
            "\n",
            "[0. 0. 0.] \t 0.5197\n",
            "[0. 0. 1.] \t 0.0\n",
            "[0. 1. 0.] \t 0.0\n",
            "[0. 1. 1.] \t 0.10138333333333334\n",
            "[1. 0. 0.] \t 0.06208333333333333\n",
            "[1. 0. 1.] \t 0.0\n",
            "[1. 1. 0.] \t 0.0\n",
            "[1. 1. 1.] \t 0.31683333333333336\n",
            "\n",
            "[0. 0. 0.] \t 0.5479833333333334\n",
            "[0. 0. 1.] \t 0.0\n",
            "[0. 1. 0.] \t 0.0\n",
            "[0. 1. 1.] \t 0.10193333333333333\n",
            "[1. 0. 0.] \t 0.05366666666666667\n",
            "[1. 0. 1.] \t 0.0\n",
            "[1. 1. 0.] \t 0.0\n",
            "[1. 1. 1.] \t 0.29641666666666666\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzKdVS04pQOv",
        "outputId": "ccc5d798-f5b9-4195-d79e-4175ccf5c64f"
      },
      "source": [
        "np.asarray(S_forest.predict_proba(X_test)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 60000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTCkXRW-YCwV"
      },
      "source": [
        "#Combine models: Model voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XgSUjckYKzv"
      },
      "source": [
        "No funciono, habria que combinarlos de otra manera, como usar las predicciones como features y entrenar un modelo que las use para relizar las predicciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsG1aaQStHtq",
        "outputId": "38b5ef18-f0e0-484f-f081-4a8f4286ff66"
      },
      "source": [
        "from sklearn.ensemble import VotingRegressor\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[(model.name, model) for model in list_models],\n",
        "    voting = \"soft\"\n",
        ")\n",
        "voting_clf.fit(X_test, y_test.values[:, 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('forest300',\n",
              "                              smodel(load_from_file=None, name='forest300')),\n",
              "                             ('forest_drop300',\n",
              "                              smodel(load_from_file=None,\n",
              "                                     name='forest_drop300')),\n",
              "                             ('forest_join300',\n",
              "                              smodel(load_from_file=None,\n",
              "                                     name='forest_join300')),\n",
              "                             ('ada20_1500',\n",
              "                              smodel(load_from_file=None, name='ada20_1500'))],\n",
              "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
              "                 weights=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7FlLbFEtldj",
        "outputId": "96ec5d5c-2aee-4cc5-83da-e5f71dd388ab"
      },
      "source": [
        "voting_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, ..., 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM-Ma61PvMS6",
        "outputId": "03292398-05af-428e-d7b4-8398abad66dd"
      },
      "source": [
        "accuracy(voting_clf, X_val, y_val.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8339\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrBUCDUTulwB",
        "outputId": "cc769f0a-da3b-4b7f-c535-596609f36d09"
      },
      "source": [
        "for model in list_models:\n",
        "  print(model.name, model.y_pred_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "forest300 [[1.         0.        ]\n",
            " [0.47666667 0.52333333]\n",
            " [0.01333333 0.98666667]\n",
            " ...\n",
            " [0.15333333 0.84666667]\n",
            " [1.         0.        ]\n",
            " [0.05       0.95      ]]\n",
            "forest_drop300 [[1.         0.        ]\n",
            " [0.52666667 0.47333333]\n",
            " [0.09       0.91      ]\n",
            " ...\n",
            " [0.12       0.88      ]\n",
            " [1.         0.        ]\n",
            " [0.05333333 0.94666667]]\n",
            "forest_pca300 [[0.99333333 0.00666667]\n",
            " [0.48       0.52      ]\n",
            " [0.05666667 0.94333333]\n",
            " ...\n",
            " [0.39333333 0.60666667]\n",
            " [0.77333333 0.22666667]\n",
            " [0.37666667 0.62333333]]\n",
            "forest_join300 [[1.         0.        ]\n",
            " [0.41666667 0.58333333]\n",
            " [0.03333333 0.96666667]\n",
            " ...\n",
            " [0.29333333 0.70666667]\n",
            " [1.         0.        ]\n",
            " [0.16333333 0.83666667]]\n",
            "extra150 [[0.92666667 0.07333333]\n",
            " [0.3        0.7       ]\n",
            " [0.08666667 0.91333333]\n",
            " ...\n",
            " [0.36       0.64      ]\n",
            " [0.83333333 0.16666667]\n",
            " [0.26666667 0.73333333]]\n",
            "neigh40 [[0.94649888 0.05350112]\n",
            " [0.44606023 0.55393977]\n",
            " [0.43672286 0.56327714]\n",
            " ...\n",
            " [0.48703731 0.51296269]\n",
            " [0.90675317 0.09324683]\n",
            " [0.42990104 0.57009896]]\n",
            "ada20_1500 [[0.50583051 0.49416949]\n",
            " [0.50332846 0.49667154]\n",
            " [0.49954339 0.50045661]\n",
            " ...\n",
            " [0.48985668 0.51014332]\n",
            " [0.50578251 0.49421749]\n",
            " [0.49350375 0.50649625]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "Mpg8WqB1x554",
        "outputId": "88029790-eb78-409e-a837-97d72b0a226a"
      },
      "source": [
        "X_preds = np.zeros_like(y_test.values[:, 0])\n",
        "for model in list_models:\n",
        "  X_preds = np.concatenate(a, model.predict(X_test), axis = 1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ace87d2787f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mX_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44CsxUNZyhQE"
      },
      "source": [
        "final = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "1Do-BkgYyet5",
        "outputId": "685b65ad-93d0-4d19-c65d-7aeb56d45f29"
      },
      "source": [
        "X_preds.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a9048e362d5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_preds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThXEtpTCDgki"
      },
      "source": [
        "#Predict\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3Uw2ejNeRk2"
      },
      "source": [
        "hackathon_data_clean = clean_data(hackathon_data, testing = True)\n",
        "hackathon_data_clean.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlepVfYArvqX"
      },
      "source": [
        "prediction = pd.DataFrame()\n",
        "\n",
        "prediction['target_r'] = y_pred_h[:,0]\n",
        "prediction['target_g'] = y_pred_h[:,1]\n",
        "prediction['target_b'] = y_pred_h[:,2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUAiDibUewkN"
      },
      "source": [
        "prediction.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEilx20TJHjj"
      },
      "source": [
        "#Submit predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcD35qeZhf5S"
      },
      "source": [
        "API_KEY = \"____\"\n",
        "\n",
        "r = requests.post(\"https://hackathon.datacrunch.com/api/submit\",\n",
        "    files = {\n",
        "        \"file\": (\"x\", prediction.to_csv().encode('ascii'))\n",
        "    },\n",
        "    data = {\n",
        "        \"apiKey\": API_KEY\n",
        "    },\n",
        ")\n",
        "\n",
        "if r.status_code == 200:\n",
        "    print(\"Submission submitted :)\")\n",
        "elif r.status_code == 423:\n",
        "    print(\"ERR: Submissions are close\")\n",
        "    print(\"The submissions are not enabled because the hackathon hasn't started yet or is already finished.\")\n",
        "    print(\"Or the server is currently crunching the submitted files, please wait some time before retrying.\")\n",
        "elif r.status_code == 422:\n",
        "    print(\"ERR: API Key is missing or empty\")\n",
        "    print(\"Did you forget to fill the API_KEY variable?\")\n",
        "elif r.status_code == 404:\n",
        "    print(\"ERR: Unknown API Key\")\n",
        "    print(\"You should check that the provided API key is valid and is the same a the one you've received by email.\")\n",
        "elif r.status_code == 400:\n",
        "    print(\"ERR: The file must not be empty\")\n",
        "    print(\"You have send a empty file.\")\n",
        "else:\n",
        "    print(\"ERR: Server returned: \" + str(r.status_code))\n",
        "    print(\"Ouch! It seems that we were not expecting this kind of result from the server, if the probleme persist, contact a cruncher.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}